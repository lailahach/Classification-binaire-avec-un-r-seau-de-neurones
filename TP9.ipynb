{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lailahach/Classification-binaire-avec-un-r-seau-de-neurones/blob/main/TP9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39zXLaT5i6D"
      },
      "source": [
        "# **Exercice 1: Implémentation des modèles VGG19, ResNet34 et DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suvZhJnitJsX",
        "outputId": "f754f04a-2bc7-4b07-a0a2-d62bd56e3536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training VGG19...\n",
            "Epoch 1: Loss=5.6981, Train Acc=10.02%\n",
            "Training ResNet34...\n",
            "Epoch 1: Loss=1.4052, Train Acc=48.57%\n",
            "Training DenseNet121...\n",
            "Epoch 1: Loss=1.2915, Train Acc=53.16%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "# =============================================\n",
        "# Préparation du dataset (CIFAR-10 par exemple)\n",
        "# =============================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),   # au lieu de 224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                     (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# ======================\n",
        "# Chargement des modèles\n",
        "# ======================\n",
        "# Définir le device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "vgg19 = models.vgg19(weights=None)\n",
        "vgg19.classifier[6] = nn.Linear(4096, 10)\n",
        "vgg19 = vgg19.to(device)\n",
        "\n",
        "# ResNet34\n",
        "resnet34 = models.resnet34(pretrained=False, num_classes=10).to(device)\n",
        "\n",
        "# DenseNet121\n",
        "densenet121 = models.densenet121(pretrained=False, num_classes=10).to(device)\n",
        "\n",
        "models_dict = {\"VGG19\": vgg19, \"ResNet34\": resnet34, \"DenseNet121\": densenet121}\n",
        "\n",
        "# =======================\n",
        "# Fonction d'entraînement\n",
        "# =======================\n",
        "def train_model(model, epochs=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        acc = 100. * correct / total\n",
        "        print(f\"Epoch {epoch+1}: Loss={running_loss/len(trainloader):.4f}, Train Acc={acc:.2f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# =======================================\n",
        "# Exemple d'entraînement\n",
        "# =======================================\n",
        "#trained_vgg19 = train_model(vgg19, epochs=5)\n",
        "for name, model in models_dict.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    trained_model = train_model(model, epochs=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJVBdUJutN1j",
        "outputId": "43d3b016-6cea-438b-bdc7-d611fb75187b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, applications\n",
        "\n",
        "# ===========================\n",
        "# Chargement dataset CIFAR-10\n",
        "# ===========================\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "x_train = tf.image.resize(x_train, (224,224)) / 255.0\n",
        "x_test  = tf.image.resize(x_test, (224,224)) / 255.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPKNzHrGOctX"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv2bZO7tNy3M",
        "outputId": "1ff006c4-8c2e-4211-c7be-2398a71312d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training VGG19 ...\n",
            "Epoch 1/5\n",
            "\u001b[1m 32/782\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:50:59\u001b[0m 100s/step - accuracy: 0.0961 - loss: 92.0849"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# Définition des modèles\n",
        "# ======================\n",
        "vgg19 = applications.VGG19(weights=None, classes=10, input_shape=(224,224,3))\n",
        "resnet34 = applications.ResNet50(weights=None, classes=10, input_shape=(224,224,3))  # pas de ResNet34 natif, mais dispo via tf-keras-applications\n",
        "densenet121 = applications.DenseNet121(weights=None, classes=10, input_shape=(224,224,3))\n",
        "\n",
        "models_dict = {\"VGG19\": vgg19, \"ResNet34\": resnet34, \"DenseNet121\": densenet121}\n",
        "\n",
        "# ==========================\n",
        "# Compilation & Entraînement\n",
        "# ==========================\n",
        "for name, model in models_dict.items():\n",
        "    print(f\"\\nTraining {name} ...\")\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
        "                        validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr3WMDfv5XSd"
      },
      "source": [
        "# **Exercice 2 : Utilisation de poids pré-entraînés**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "#  1. Monter Google Drive\n",
        "# =======================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =======================\n",
        "#  2. Décompresser PlantVillage.zip\n",
        "# =======================\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/PlantVillage.zip\"\n",
        "extract_path = \"/content/PlantVillage\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Dataset extrait !\")\n",
        "else:\n",
        "    print(\"Dataset déjà extrait.\")\n",
        "\n",
        "# =======================\n",
        "#  3. Créer dossiers train / val\n",
        "# =======================\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "train_dir = \"/content/PlantVillage/train\"\n",
        "val_dir   = \"/content/PlantVillage/val\"\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "    base_dir = os.path.join(extract_path, \"plantvillage dataset/color\")  # change en grayscale si besoin\n",
        "    classes = os.listdir(base_dir)\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(base_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        split = int(0.8 * len(images))  # 80% train, 20% val\n",
        "        train_images = images[:split]\n",
        "        val_images   = images[split:]\n",
        "\n",
        "        for img in train_images:\n",
        "            shutil.copy(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
        "        for img in val_images:\n",
        "            shutil.copy(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))\n",
        "\n",
        "    print(\" Séparation train / val terminée\")\n",
        "else:\n",
        "    print(\" Dossiers train/val déjà prêts\")\n",
        "\n",
        "# =======================\n",
        "#  4. Charger avec TensorFlow\n",
        "# =======================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# =======================\n",
        "#  5. Prétraitement\n",
        "# =======================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8kTyYPI3FXh",
        "outputId": "7c914e72-1cde-4a32-9adb-9953bd5f6727"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset déjà extrait.\n",
            " Dossiers train/val déjà prêts\n",
            "Found 51030 files belonging to 38 classes.\n",
            "Found 17426 files belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Complet**"
      ],
      "metadata": {
        "id": "jisM6tJJ-f2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "Crn49UhR5Jkv",
        "outputId": "476dd87c-3e0d-4689-ec44-99f52e36feed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "✅ Dataset organisé en train/ et val/\n",
            "Nombre de classes: 38\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 548M/548M [00:04<00:00, 134MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 50.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 45.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1515728967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mdensenet121\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"densenet121\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m \u001b[0mvgg19_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg19_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg19_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0mresnet34_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0mdensenet121_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet121_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet121_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensenet121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1515728967.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, lr)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil, random\n",
        "\n",
        "# ================================\n",
        "# 1. Préparation du device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================\n",
        "# 2. Préparation du dataset PlantVillage\n",
        "# ================================\n",
        "# Choix de la variante : color, grayscale ou segmented\n",
        "source_dir = \"/content/PlantVillage/plantvillage dataset/color\"\n",
        "base_dir = \"/content/PlantVillage_split\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "\n",
        "# ================================\n",
        "# 3. Chargement des données\n",
        "# ================================\n",
        "data_dir = base_dir\n",
        "batch_size = 32\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
        "    for x in [\"train\", \"val\"]\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    for x in [\"train\", \"val\"]\n",
        "}\n",
        "\n",
        "class_names = image_datasets[\"train\"].classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Nombre de classes: {num_classes}\")\n",
        "\n",
        "# ================================\n",
        "# 4. Fonction de création de modèle\n",
        "# ================================\n",
        "def create_model(model_name, num_classes):\n",
        "    if model_name == \"vgg19\":\n",
        "        model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    elif model_name == \"resnet34\":\n",
        "        model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    elif model_name == \"densenet121\":\n",
        "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "# ================================\n",
        "# 5. Fonction d’entraînement\n",
        "# ================================\n",
        "def train_model(model, epochs=5, lr=1e-3):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses, val_losses, val_accs = [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in dataloaders[\"train\"]:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets[\"train\"])\n",
        "        train_losses.append(epoch_loss)\n",
        "\n",
        "        # --- Évaluation ---\n",
        "        model.eval()\n",
        "        val_loss, correct = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloaders[\"val\"]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(image_datasets[\"val\"])\n",
        "        acc = correct / len(image_datasets[\"val\"])\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(acc)\n",
        "\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {acc:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses, val_accs\n",
        "\n",
        "# ================================\n",
        "# 6. Exécution pour chaque modèle\n",
        "# ================================\n",
        "vgg19 = create_model(\"vgg19\", num_classes)\n",
        "resnet34 = create_model(\"resnet34\", num_classes)\n",
        "densenet121 = create_model(\"densenet121\", num_classes)\n",
        "\n",
        "vgg19_train, vgg19_val, vgg19_acc = train_model(vgg19, epochs=3)\n",
        "resnet34_train, resnet34_val, resnet34_acc = train_model(resnet34, epochs=3)\n",
        "densenet121_train, densenet121_val, densenet121_acc = train_model(densenet121, epochs=3)\n",
        "\n",
        "# ================================\n",
        "# 7. Visualisation des résultats\n",
        "# ================================\n",
        "plt.plot(vgg19_acc, label=\"VGG19\")\n",
        "plt.plot(resnet34_acc, label=\"ResNet34\")\n",
        "plt.plot(densenet121_acc, label=\"DenseNet121\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Comparaison des modèles sur PlantVillage\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMeSV5ne3gVF"
      },
      "source": [
        "**ResNet34 sous échantillon**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3P-MqIr1U2u",
        "outputId": "e25dbfb9-f554-4030-b4c5-bf916f629056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚡ Split déjà fait, on continue...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2 | Train Loss: 0.5715 Acc: 86.41% | Val Loss: 0.2667 Acc: 92.24%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===============================\n",
        "# 1. Préparation Dataset (optimisé)\n",
        "# ===============================\n",
        "data_dir = \"/content/PlantVillage\"   # dossier original\n",
        "train_dir = \"/content/PlantVillage_split/train\"\n",
        "val_dir   = \"/content/PlantVillage_split/val\"\n",
        "\n",
        "# Faire le split UNE SEULE FOIS\n",
        "if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    split_ratio = 0.8  # 80% train / 20% val\n",
        "    max_per_class = 200  # limiter à 200 images par classe pour test rapide\n",
        "\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)\n",
        "        images = images[:max_per_class]  # limiter la taille\n",
        "\n",
        "        split_point = int(len(images) * split_ratio)\n",
        "        train_images = images[:split_point]\n",
        "        val_images   = images[split_point:]\n",
        "\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "        for img in train_images:\n",
        "            shutil.copy(os.path.join(class_path, img),\n",
        "                        os.path.join(train_dir, class_name, img))\n",
        "        for img in val_images:\n",
        "            shutil.copy(os.path.join(class_path, img),\n",
        "                        os.path.join(val_dir, class_name, img))\n",
        "    print(\" Split terminé (avec sous-échantillon).\")\n",
        "else:\n",
        "    print(\" Split déjà fait, on continue...\")\n",
        "\n",
        "# ===============================\n",
        "# 2. Transforms & DataLoaders\n",
        "# ===============================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_data   = datasets.ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "class_names = train_data.classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ===============================\n",
        "# 3. Entraînement ResNet34 (seul)\n",
        "# ===============================\n",
        "model = models.resnet34(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "num_epochs = 2  # test rapide (peut monter ensuite)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
        "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# ===============================\n",
        "# 4. Évaluation\n",
        "# ===============================\n",
        "y_true, y_pred = [], []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "print(\"\\n Rapport de classification :\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Courbes de loss\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Courbes de Loss (ResNet34)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTDjtGfg-eb5"
      },
      "source": [
        "# **Exercice 3: Transfert learning avec EfficientNet et ViT**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# Transfer Learning on PlantVillage with EfficientNet & ViT\n",
        "# PyTorch + timm — Colab-ready, with Drive loading & auto split\n",
        "# ============================================================\n",
        "\n",
        "import os, time, json, random, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Optional: Mount Google Drive (uncomment if needed)\n",
        "# ---------------------------\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  # Then point SOURCE_DIR to a folder in Drive\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Configs (adapt paths here)\n",
        "# ---------------------------\n",
        "#   SOURCE_DIR doit pointer vers le dossier qui contient directement les classes\n",
        "#    (par ex. \".../plantvillage dataset/color\", ou \".../grayscale\", ou \".../segmented\")\n",
        "SOURCE_DIR = Path(\"/content/PlantVillage/plantvillage dataset/color\")\n",
        "\n",
        "# Dossier cible avec la structure standard attendue par le script: train/val/test\n",
        "DATA_DIR   = Path(\"/content/PlantVillage\")        # racine de sortie\n",
        "SPLIT_DIR  = DATA_DIR                             # on garde train/val/test sous /content/PlantVillage\n",
        "TRAIN_DIR  = SPLIT_DIR / \"train\"\n",
        "VAL_DIR    = SPLIT_DIR / \"val\"\n",
        "TEST_DIR   = SPLIT_DIR / \"test\"\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/outputs_efficientnet_vit\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Split & sampling\n",
        "TRAIN_RATIO   = 0.7  # 70% train\n",
        "VAL_RATIO     = 0.15 # 15% val\n",
        "TEST_RATIO    = 0.15 # 15% test\n",
        "MAX_PER_CLASS = None  # ex: 300 pour accélérer les tests; None = prendre tout\n",
        "\n",
        "# Training\n",
        "IMG_SIZE      = 224\n",
        "BATCH_SIZE    = 32\n",
        "WORKERS       = 2        # Colab: 2 ou 4\n",
        "SEED          = 42\n",
        "EPOCHS_FREEZE = 5\n",
        "EPOCHS_FT     = 10\n",
        "UNFREEZE_RATIO= 0.3      # Unfreeze top 30% layers during fine-tuning\n",
        "\n",
        "# Reproducibility\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "USE_AMP = torch.cuda.is_available()  # mixed precision on GPU\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Build train/val/test from SOURCE_DIR (only once)\n",
        "# ---------------------------\n",
        "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
        "\n",
        "def is_image(fname: str) -> bool:\n",
        "    return Path(fname).suffix.lower() in IMG_EXTS\n",
        "\n",
        "def ensure_split_from_source(source_dir: Path, train_dir: Path, val_dir: Path, test_dir: Path,\n",
        "                             train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
        "                             max_per_class=None):\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n",
        "\n",
        "    if train_dir.exists() and val_dir.exists() and test_dir.exists():\n",
        "        print(\"Split already exists. Skipping creation.\")\n",
        "        return\n",
        "\n",
        "    print(\"🔧 Creating train/val/test split from:\", source_dir)\n",
        "    for d in [train_dir, val_dir, test_dir]:\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    classes = [c for c in os.listdir(source_dir) if (source_dir / c).is_dir()]\n",
        "    classes.sort()\n",
        "    for cls in classes:\n",
        "        src_cls = source_dir / cls\n",
        "        imgs = [f for f in os.listdir(src_cls) if is_image(f)]\n",
        "        random.shuffle(imgs)\n",
        "\n",
        "        if max_per_class is not None:\n",
        "            imgs = imgs[:max_per_class]\n",
        "\n",
        "        n = len(imgs)\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val   = int(n * val_ratio)\n",
        "        n_test  = n - n_train - n_val\n",
        "\n",
        "        splits = {\n",
        "            train_dir / cls: imgs[:n_train],\n",
        "            val_dir   / cls: imgs[n_train:n_train+n_val],\n",
        "            test_dir  / cls: imgs[n_train+n_val:]\n",
        "        }\n",
        "\n",
        "        for dst_dir, files in splits.items():\n",
        "            dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for f in files:\n",
        "                src = src_cls / f\n",
        "                dst = dst_dir / f\n",
        "                if not dst.exists():\n",
        "                    shutil.copy2(src, dst)\n",
        "    print(\"Split done:\", str(train_dir), str(val_dir), str(test_dir))\n",
        "\n",
        "ensure_split_from_source(\n",
        "    SOURCE_DIR, TRAIN_DIR, VAL_DIR, TEST_DIR,\n",
        "    train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, test_ratio=TEST_RATIO,\n",
        "    max_per_class=MAX_PER_CLASS\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Datasets & Dataloaders\n",
        "# ---------------------------\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tf)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR, transform=val_tf)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR, transform=val_tf)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "print(f\"Classes ({num_classes}):\", train_ds.classes)\n",
        "\n",
        "pin_memory = torch.cuda.is_available()\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=WORKERS, pin_memory=pin_memory)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=pin_memory)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Models (EfficientNet-B0, ViT-B/16) with timm\n",
        "# ---------------------------\n",
        "try:\n",
        "    import timm\n",
        "except ImportError:\n",
        "    raise SystemExit(\" timm not installed. Please run: pip install timm\")\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def build_model(name: str, num_classes: int):\n",
        "    \"\"\"Create a pretrained model and replace its classifier head.\"\"\"\n",
        "    name_l = name.lower()\n",
        "    if name_l in [\"efficientnet_b0\", \"efficientnet\"]:\n",
        "        model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=num_classes)\n",
        "    elif name_l in [\"vit_b16\", \"vit\", \"vit_base_patch16_224\", \"vit_base_patch16_224.augreg_in21k_ft_in1k\"]:\n",
        "        # default vit_base_patch16_224\n",
        "        model = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model. Use 'efficientnet_b0' or 'vit_base_patch16_224'.\")\n",
        "    return model.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Utils: training, evaluation, plots\n",
        "# ---------------------------\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total, loss_sum = 0, 0, 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_targets, all_preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss_sum += loss.item() * x.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            all_targets.extend(y.detach().cpu().tolist())\n",
        "            all_preds.extend(preds.detach().cpu().tolist())\n",
        "    avg_loss = loss_sum / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc, np.array(all_targets), np.array(all_preds)\n",
        "\n",
        "def plot_curves(log, title, out_prefix):\n",
        "    epochs = range(1, len(log[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, log[\"train_loss\"], label=\"train\")\n",
        "    plt.plot(epochs, log[\"val_loss\"], label=\"val\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"{title} — Loss\"); plt.legend(); plt.grid(True)\n",
        "    plt.savefig(f\"{out_prefix}_loss.png\", dpi=140)\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, log[\"train_acc\"], label=\"train\")\n",
        "    plt.plot(epochs, log[\"val_acc\"], label=\"val\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(f\"{title} — Accuracy\"); plt.legend(); plt.grid(True)\n",
        "    plt.savefig(f\"{out_prefix}_acc.png\", dpi=140)\n",
        "    plt.close()\n",
        "\n",
        "def count_trainable(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def unfreeze_top_layers(model, ratio: float = 0.3):\n",
        "    \"\"\"Unfreeze last 'ratio' of layers for fine-tuning (generic heuristic).\"\"\"\n",
        "    layers = [m for m in model.modules()]\n",
        "    cutoff = int(len(layers) * (1 - ratio))\n",
        "\n",
        "    # freeze all\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    # unfreeze top\n",
        "    for m in layers[cutoff:]:\n",
        "        for p in m.parameters(recurse=True):\n",
        "            p.requires_grad = True\n",
        "\n",
        "def train_two_stages(model_name: str,\n",
        "                     epochs_freeze=EPOCHS_FREEZE, epochs_ft=EPOCHS_FT,\n",
        "                     unfreeze_ratio=UNFREEZE_RATIO):\n",
        "    model = build_model(model_name, num_classes)\n",
        "\n",
        "    # Stage 1: freeze backbone, train only head\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # Re-enable classifier parameters depending on model attribute\n",
        "    if hasattr(model, 'classifier') and isinstance(model.classifier, nn.Module):\n",
        "        for p in model.classifier.parameters():\n",
        "            p.requires_grad = True\n",
        "    elif hasattr(model, 'head') and isinstance(model.head, nn.Module):  # ViT in timm\n",
        "        for p in model.head.parameters():\n",
        "            p.requires_grad = True\n",
        "    else:\n",
        "        # fallback: unfreeze last layer's params\n",
        "        for p in list(model.parameters())[-2:]:\n",
        "            p.requires_grad = True\n",
        "\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                            lr=3e-4, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "    log = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "\n",
        "    # ---- Stage 1 training ----\n",
        "    for epoch in range(1, epochs_freeze + 1):\n",
        "        model.train()\n",
        "        tloss, tcorrect, ttotal = 0.0, 0, 0\n",
        "        t0 = time.time()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            tloss += loss.item() * x.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            tcorrect += (preds == y).sum().item()\n",
        "            ttotal += y.size(0)\n",
        "        train_loss = tloss / ttotal\n",
        "        train_acc  = tcorrect / ttotal\n",
        "\n",
        "        val_loss, val_acc, _, _ = evaluate(model, val_loader)\n",
        "        log[\"train_loss\"].append(train_loss)\n",
        "        log[\"val_loss\"].append(val_loss)\n",
        "        log[\"train_acc\"].append(train_acc)\n",
        "        log[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"[Stage1][{model_name}] Epoch {epoch}/{epochs_freeze} \"\n",
        "              f\"| Train {train_loss:.4f}/{train_acc:.4f} \"\n",
        "              f\"| Val {val_loss:.4f}/{val_acc:.4f} \"\n",
        "              f\"| {(time.time()-t0):.1f}s\")\n",
        "\n",
        "    # ---- Stage 2: fine-tune top layers ----\n",
        "    unfreeze_top_layers(model, ratio=unfreeze_ratio)\n",
        "    print(f\"🔓 Unfreezing top {int(unfreeze_ratio*100)}% layers. \"\n",
        "          f\"Trainable params: {count_trainable(model):,}\")\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                            lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    for epoch in range(1, epochs_ft + 1):\n",
        "        model.train()\n",
        "        tloss, tcorrect, ttotal = 0.0, 0, 0\n",
        "        t0 = time.time()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            tloss += loss.item() * x.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            tcorrect += (preds == y).sum().item()\n",
        "            ttotal += y.size(0)\n",
        "        train_loss = tloss / ttotal\n",
        "        train_acc  = tcorrect / ttotal\n",
        "\n",
        "        val_loss, val_acc, _, _ = evaluate(model, val_loader)\n",
        "        log[\"train_loss\"].append(train_loss)\n",
        "        log[\"val_loss\"].append(val_loss)\n",
        "        log[\"train_acc\"].append(train_acc)\n",
        "        log[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"[Stage2][{model_name}] Epoch {epoch}/{epochs_ft} \"\n",
        "              f\"| Train {train_loss:.4f}/{train_acc:.4f} \"\n",
        "              f\"| Val {val_loss:.4f}/{val_acc:.4f} \"\n",
        "              f\"| {(time.time()-t0):.1f}s\")\n",
        "\n",
        "    # Save training curves\n",
        "    with open(OUTPUT_DIR / f\"{model_name}_history.json\", \"w\") as f:\n",
        "        json.dump(log, f)\n",
        "    plot_curves(log, model_name, str(OUTPUT_DIR / model_name))\n",
        "\n",
        "    # Test evaluation\n",
        "    test_loss, test_acc, y_true, y_pred = evaluate(model, test_loader)\n",
        "    print(f\"\\n[Test][{model_name}] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
        "\n",
        "    # Classification report & confusion matrix\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    report = classification_report(y_true, y_pred, target_names=train_ds.classes, digits=4)\n",
        "    print(report)\n",
        "    with open(OUTPUT_DIR / f\"{model_name}_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    # Confusion matrix plot\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(9, 8))\n",
        "    sns.heatmap(cm, cmap=\"Blues\", square=True, cbar=True)\n",
        "    plt.title(f\"Confusion Matrix — {model_name}\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUTPUT_DIR / f\"{model_name}_confusion.png\", dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Save model weights\n",
        "    torch.save(model.state_dict(), OUTPUT_DIR / f\"{model_name}_finetuned.pt\")\n",
        "\n",
        "    return {\"test_loss\": test_loss, \"test_acc\": test_acc}\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Run both models\n",
        "# ---------------------------\n",
        "results = {}\n",
        "for name in [\"efficientnet_b0\", \"vit_base_patch16_224\"]:\n",
        "    print(f\"\\n===== Training {name} on PlantVillage =====\")\n",
        "    results[name] = train_two_stages(name)\n",
        "\n",
        "# Summary CSV\n",
        "import csv\n",
        "with open(OUTPUT_DIR / \"summary_results.csv\", \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"model\", \"test_loss\", \"test_acc\"])\n",
        "    for k, v in results.items():\n",
        "        w.writerow([k, v[\"test_loss\"], v[\"test_acc\"]])\n",
        "\n",
        "print(\"\\n Done. Outputs saved to:\", OUTPUT_DIR.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y45aonT8Prc",
        "outputId": "022d5430-1691-41e2-a4d3-aba2e2234d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Split already exists. Skipping creation.\n",
            "Classes (38): ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
            "\n",
            "===== Training efficientnet_b0 on PlantVillage =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-239511846.py:256: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
            "/tmp/ipython-input-239511846.py:268: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOYnQcPC4mGu1tF5eZfIyBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}